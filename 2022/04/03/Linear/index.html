<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.1.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.0.0/css/all.min.css" integrity="sha256-jTIdiMuX/e3DGJUGwl3pKSxuc6YOuqtJYkM0bGQESA4=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Mist","darkmode":true,"version":"8.10.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="向量究竟是什么？向量的本质向量：可以看作在空间中向某个方法移动一段距离。数学形式： \left[ \begin{matrix} -2 \\ 3  \end{matrix} \right]图像形式：     从上到下：第一个数表示沿x轴移动的距离，第二个数表示沿y轴移动的距离。 向量的计算向量加法与向量数乘贯穿线性代数始终。  向量加法数字角度： \left[ \begin{matrix} 1 \\">
<meta property="og:type" content="article">
<meta property="og:title" content="Linear">
<meta property="og:url" content="http://example.com/2022/04/03/Linear/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="向量究竟是什么？向量的本质向量：可以看作在空间中向某个方法移动一段距离。数学形式： \left[ \begin{matrix} -2 \\ 3  \end{matrix} \right]图像形式：     从上到下：第一个数表示沿x轴移动的距离，第二个数表示沿y轴移动的距离。 向量的计算向量加法与向量数乘贯穿线性代数始终。  向量加法数字角度： \left[ \begin{matrix} 1 \\">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/01.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/02.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/03.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/04.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/05.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/06.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/07.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/08.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/09.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/01.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/10.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/11.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/12.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/13.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/02.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/03.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/04.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/05.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/06.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/14.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/15.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/16.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/17.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/18.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/19.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/20.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/21.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/07.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/08.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/09.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/22.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/23.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/24.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/10.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/11.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/12.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/25.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/26.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/27.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/28.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/29.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/30.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/31.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/32.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/33.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/34.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/35.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/36.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/37.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/38.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/39.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/40.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/41.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/42.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/43.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/44.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/45.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/13.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/14.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/15.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/16.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/17.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/18.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/19.gif">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/47.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/48.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/49.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/50.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/51.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/52.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/53.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/54.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/55.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/56.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/57.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/60.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/58.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/59.png">
<meta property="og:image" content="http://example.com/2022/04/03/Linear/Image/61.png">
<meta property="article:published_time" content="2022-04-03T03:44:51.000Z">
<meta property="article:modified_time" content="2022-04-03T03:45:30.474Z">
<meta property="article:author" content="Voimmamored">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/2022/04/03/Linear/Image/01.png">


<link rel="canonical" href="http://example.com/2022/04/03/Linear/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"en","comments":true,"permalink":"http://example.com/2022/04/03/Linear/","path":"2022/04/03/Linear/","title":"Linear"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Linear | Hexo</title>
  





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Hexo</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="nav-number">1.</span> <span class="nav-text">向量究竟是什么？</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E7%9A%84%E6%9C%AC%E8%B4%A8"><span class="nav-number">1.1.</span> <span class="nav-text">向量的本质</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">1.2.</span> <span class="nav-text">向量的计算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%8A%A0%E6%B3%95"><span class="nav-number">1.2.1.</span> <span class="nav-text">向量加法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E6%95%B0%E4%B9%98"><span class="nav-number">1.2.2.</span> <span class="nav-text">向量数乘</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88%E3%80%81%E5%BC%A0%E6%88%90%E7%9A%84%E7%A9%BA%E9%97%B4%E4%B8%8E%E5%9F%BA"><span class="nav-number">2.</span> <span class="nav-text">线性组合、张成的空间与基</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E5%90%91%E9%87%8F"><span class="nav-number">2.1.</span> <span class="nav-text">基向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E7%BB%84%E5%90%88"><span class="nav-number">2.2.</span> <span class="nav-text">线性组合</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%BC%A0%E6%88%90%E7%9A%84%E7%A9%BA%E9%97%B4"><span class="nav-number">2.3.</span> <span class="nav-text">张成的空间</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2"><span class="nav-number">3.</span> <span class="nav-text">矩阵与线性变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2"><span class="nav-number">3.1.</span> <span class="nav-text">线性变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5"><span class="nav-number">3.2.</span> <span class="nav-text">矩阵</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E4%B8%8E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E5%A4%8D%E5%90%88"><span class="nav-number">4.</span> <span class="nav-text">矩阵乘法与线性变换复合</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%8D%E5%90%88%E5%8F%98%E6%8D%A2"><span class="nav-number">4.1.</span> <span class="nav-text">复合变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95"><span class="nav-number">4.2.</span> <span class="nav-text">矩阵乘法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E7%9F%A9%E9%98%B5%E4%B9%98%E6%B3%95%E8%BF%90%E7%AE%97%E5%8E%9F%E7%90%86"><span class="nav-number">4.2.1.</span> <span class="nav-text">矩阵乘法运算原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A4%8D%E5%90%88%E5%8F%98%E6%8D%A2%E7%9A%84%E8%BF%90%E7%AE%97%E5%BE%8B"><span class="nav-number">4.2.2.</span> <span class="nav-text">复合变换的运算律</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F"><span class="nav-number">5.</span> <span class="nav-text">行列式</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E6%83%85%E5%86%B5"><span class="nav-number">5.1.</span> <span class="nav-text">二维情况</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E4%B8%8B%E8%A1%8C%E5%88%97%E5%BC%8F%E8%B4%9F%E5%80%BC%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">5.1.1.</span> <span class="nav-text">二维下行列式负值的意义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4%E6%83%85%E5%86%B5"><span class="nav-number">5.2.</span> <span class="nav-text">三维情况</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4%E4%B8%8B%E8%A1%8C%E5%88%97%E5%BC%8F%E8%B4%9F%E5%80%BC%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">5.2.1.</span> <span class="nav-text">三维下行列式负值的意义</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%A1%8C%E5%88%97%E5%BC%8F%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">5.3.</span> <span class="nav-text">行列式的计算</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E9%98%B6%E8%A1%8C%E5%88%97%E5%BC%8F"><span class="nav-number">5.3.1.</span> <span class="nav-text">二阶行列式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E9%98%B6%E8%A1%8C%E5%88%97%E5%BC%8F"><span class="nav-number">5.3.2.</span> <span class="nav-text">三阶行列式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%80%86%E7%9F%A9%E9%98%B5%E3%80%81%E5%88%97%E7%A9%BA%E9%97%B4%E3%80%81%E7%A7%A9%E4%B8%8E%E9%9B%B6%E7%A9%BA%E9%97%B4"><span class="nav-number">6.</span> <span class="nav-text">逆矩阵、列空间、秩与零空间</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%80%86%E7%9F%A9%E9%98%B5"><span class="nav-number">6.1.</span> <span class="nav-text">逆矩阵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%97%E7%A9%BA%E9%97%B4"><span class="nav-number">6.2.</span> <span class="nav-text">列空间</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%A7%A9"><span class="nav-number">6.3.</span> <span class="nav-text">秩</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9B%B6%E7%A9%BA%E9%97%B4"><span class="nav-number">6.4.</span> <span class="nav-text">零空间</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%82%B9%E7%A7%AF%E4%B8%8E%E5%AF%B9%E5%81%B6%E6%80%A7"><span class="nav-number">7.</span> <span class="nav-text">点积与对偶性</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%9D%9E%E6%96%B9%E9%98%B5%E7%9F%A9%E9%98%B5%E7%9A%84%E6%84%8F%E4%B9%89"><span class="nav-number">7.1.</span> <span class="nav-text">非方阵矩阵的意义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%82%B9%E7%A7%AF%E7%9A%84%E8%BF%90%E7%AE%97"><span class="nav-number">7.2.</span> <span class="nav-text">点积的运算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%82%B9%E7%A7%AF%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89"><span class="nav-number">7.3.</span> <span class="nav-text">点积的几何意义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%82%B9%E7%A7%AF%E7%9A%84%E6%9C%AC%E8%B4%A8"><span class="nav-number">7.4.</span> <span class="nav-text">点积的本质</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%8F%89%E7%A7%AF%E7%9A%84%E6%A0%87%E5%87%86%E4%BB%8B%E7%BB%8D"><span class="nav-number">8.</span> <span class="nav-text">叉积的标准介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E8%A7%86%E8%A7%92"><span class="nav-number">8.1.</span> <span class="nav-text">二维视角</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E4%B8%8B%E5%8F%89%E7%A7%AF%E7%9A%84%E8%AE%A1%E7%AE%97"><span class="nav-number">8.1.1.</span> <span class="nav-text">二维下叉积的计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9C%9F%E6%AD%A3%E7%9A%84%E5%8F%89%E7%A7%AF%EF%BC%88%E4%B8%89%E7%BB%B4%E8%A7%86%E8%A7%92%EF%BC%89"><span class="nav-number">8.2.</span> <span class="nav-text">真正的叉积（三维视角）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4%E4%B8%8B%E5%8F%89%E7%A7%AF%E7%9A%84%E8%BF%90%E7%AE%97"><span class="nav-number">8.2.1.</span> <span class="nav-text">三维下叉积的运算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BB%8E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3%E5%8F%89%E7%A7%AF"><span class="nav-number">8.3.</span> <span class="nav-text">从线性变换的角度理解叉积</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%8F%89%E7%A7%AF%E7%9A%84%E8%BF%90%E7%AE%97"><span class="nav-number">8.3.1.</span> <span class="nav-text">如何理解叉积的运算</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E7%90%86%E8%A7%A3%E5%8F%89%E7%A7%AF%E7%9A%84%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89"><span class="nav-number">8.3.2.</span> <span class="nav-text">如何理解叉积的几何意义</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E5%8F%98%E6%8D%A2"><span class="nav-number">9.</span> <span class="nav-text">基变换</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%8C%E4%B8%80%E5%9D%90%E6%A0%87%E4%BA%8E%E4%B8%8D%E5%90%8C%E5%9D%90%E6%A0%87%E7%B3%BB%E9%97%B4%E7%9A%84%E8%BD%AC%E6%8D%A2"><span class="nav-number">9.1.</span> <span class="nav-text">同一坐标于不同坐标系间的转换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%80%BB%E7%BB%93"><span class="nav-number">9.2.</span> <span class="nav-text">总结</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E4%B8%8E%E7%89%B9%E5%BE%81%E5%80%BC"><span class="nav-number">10.</span> <span class="nav-text">特征向量与特征值</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E7%BB%B4%E7%A9%BA%E9%97%B4%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="nav-number">10.1.</span> <span class="nav-text">二维空间中的特征向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%B8%89%E7%BB%B4%E7%A9%BA%E9%97%B4%E7%9A%84%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F"><span class="nav-number">10.2.</span> <span class="nav-text">三维空间的特征向量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%89%B9%E5%BE%81%E5%90%91%E9%87%8F%E6%A6%82%E5%BF%B5"><span class="nav-number">10.3.</span> <span class="nav-text">特征向量概念</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%8A%BD%E8%B1%A1%E5%90%91%E9%87%8F%E7%A9%BA%E9%97%B4"><span class="nav-number">11.</span> <span class="nav-text">抽象向量空间</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BA%BF%E6%80%A7%E7%9A%84%E4%B8%A5%E6%A0%BC%E5%AE%9A%E4%B9%89"><span class="nav-number">11.1.</span> <span class="nav-text">线性的严格定义</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%87%BD%E6%95%B0%E4%B8%8E%E7%BA%BF%E6%80%A7%E4%BB%A3%E6%95%B0"><span class="nav-number">11.2.</span> <span class="nav-text">函数与线性代数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%85%8B%E8%8E%B1%E5%A7%86%E6%B3%95%E5%88%99"><span class="nav-number">12.</span> <span class="nav-text">克莱姆法则</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Voimmamored</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span>
      </div>
  </nav>
</div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2022/04/03/Linear/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Voimmamored">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hexo">
      <meta itemprop="description" content="">
    </span>
    
    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="Linear | Hexo">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Linear
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2022-04-03 11:44:51 / Modified: 11:45:30" itemprop="dateCreated datePublished" datetime="2022-04-03T11:44:51+08:00">2022-04-03</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">In</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Math/" itemprop="url" rel="index"><span itemprop="name">Math</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="向量究竟是什么？"><a href="#向量究竟是什么？" class="headerlink" title="向量究竟是什么？"></a>向量究竟是什么？</h1><h2 id="向量的本质"><a href="#向量的本质" class="headerlink" title="向量的本质"></a>向量的本质</h2><p><strong>向量</strong>：可以看作在空间中向某个方法移动一段距离。<br>数学形式：</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
-2 \\
3 
\end{matrix}
\right]</script><p>图像形式：</p>
<div align=center>
<img src="Image/01.png" width="30%">
</div>

<p>从上到下：<br>第一个数表示沿x轴移动的距离，<br>第二个数表示沿y轴移动的距离。</p>
<h2 id="向量的计算"><a href="#向量的计算" class="headerlink" title="向量的计算"></a>向量的计算</h2><p><strong>向量加法</strong>与<strong>向量数乘</strong>贯穿线性代数始终。 </p>
<h3 id="向量加法"><a href="#向量加法" class="headerlink" title="向量加法"></a>向量加法</h3><p>数字角度：</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
1 \\
2
\end{matrix}
\right] + \left[
\begin{matrix}
3 \\
-1
\end{matrix}
\right]=\left[
\begin{matrix}
1 + 3\\
2 + (-1)
\end{matrix}
\right]</script><p>图像角度：</p>
<div align=center>
<img src="Image/02.png" width="50%">
</div>

<h3 id="向量数乘"><a href="#向量数乘" class="headerlink" title="向量数乘"></a>向量数乘</h3><p>数字角度：</p>
<script type="math/tex; mode=display">2\cdot\left[\begin{matrix}
6 \\ 2
\end{matrix}\right]=\left[
\begin{matrix}
12 \\
4
\end{matrix}\right]</script><p>图像角度：</p>
<div align=center>
<img src="Image/03.png" width="50%">
</div>

<h1 id="线性组合、张成的空间与基"><a href="#线性组合、张成的空间与基" class="headerlink" title="线性组合、张成的空间与基"></a>线性组合、张成的空间与基</h1><h2 id="基向量"><a href="#基向量" class="headerlink" title="基向量"></a>基向量</h2><p>$\hat{i} 与 \hat{j}$分别是$x$轴方向与$y$轴方向的单位向量，单位长度为1，称为基向量。  </p>
<p>通过对基向量的缩放与相加可以得到其他的向量。</p>
<div align=center>
<img src="Image/04.png" width="100%">
</div>


<p>我们也可以选择其他的基向量构建不同的坐标系。  </p>
<p><img src="Image/05.png" width="50%"></p>
<p>因此，向量既可以被看作一对数字的形式：</p>
<script type="math/tex; mode=display">\left[\begin{matrix}
-0.8 \\
1.3
\end{matrix}\right]</script><p>也可以被看作一对基向量的形式：</p>
<script type="math/tex; mode=display">-0.8\vec{v} + 1.3\vec{w}</script><p>但是同一个向量用不同基向量得到的数字形式并不相同。<br><strong>每当我们用数字描述向量时，都依赖于我们正在使用的基向量。</strong> </p>
<h2 id="线性组合"><a href="#线性组合" class="headerlink" title="线性组合"></a>线性组合</h2><p><strong><script type="math/tex">a\vec{v} + b\vec{w}</script></strong><br>两个数乘向量的和被称为这两个向量的<strong>线性组合</strong>。<br>两个初始向量不共线时，可以通过线性组合得到所有的向量。<br>当两个初始向量共线时，线性组合所产生的向量的终点被限制在一条过原点的直线上。</p>
<h2 id="张成的空间"><a href="#张成的空间" class="headerlink" title="张成的空间"></a>张成的空间</h2><p>$\vec{v}和\vec{w}$全部线性组合构成的向量的集合称为它们<strong>张成的空间(span)</strong>。</p>
<p>同理，在三维空间中，两个方向不同的向量张成的空间是某个过原点的平面。<br><img src="Image/06.png" width="50%"><br>若在此时加入第三个向量$\vec{u}$，那么三个向量的线性组合会产生两种情况：<br><strong><script type="math/tex">a\vec{v} + b\vec{w} + c\vec{u}</script></strong></p>
<ol>
<li>若$\vec{u}$恰好在之前两个向量张成的平面上，即<br><strong><script type="math/tex">\vec{u} = a\vec{v} + b\vec{w}</script></strong><br>此时三个向量张成的空间还是原来的平面。  </li>
<li>若$\vec{u}$指向不同的方向，三个向量张成的空间会是整个三维空间。</li>
</ol>
<p>在多个向量的线性组合中，如果可以移除其中一个向量且不影响张成的空间，则称它们是<strong>线性相关</strong>的。<br>如果每一个向量都为张成的空间添加了新的维度，则称它们是<strong>线性不相关</strong>的。</p>
<p><strong>基向量</strong>的严格定义：向量空间的一组<strong>基</strong>是<strong>张成</strong>该空间的一个<strong>线性无关</strong>向量集。</p>
<h1 id="矩阵与线性变换"><a href="#矩阵与线性变换" class="headerlink" title="矩阵与线性变换"></a>矩阵与线性变换</h1><h2 id="线性变换"><a href="#线性变换" class="headerlink" title="线性变换"></a>线性变换</h2><p>若一个变换满足以下两点：</p>
<ol>
<li>原点保持固定。</li>
<li>直线在变换后依然保持直线状态，网格线保持平行且等距分布。 </li>
</ol>
<p>则称其为<strong>线性变换</strong>。</p>
<h2 id="矩阵"><a href="#矩阵" class="headerlink" title="矩阵"></a>矩阵</h2><p>只需要记录两个基向量$\hat{i} 与 \hat{j}$变换后的位置，就可以推断出任意向量在变换后的位置。<br>例如：</p>
<p><img src="Image/07.png" width="50%">  </p>
<p>此时满足线性组合:  </p>
<script type="math/tex; mode=display">\vec{v} = -1\hat{i} + 2\hat{j}</script><p><strong>在线性变换前后，向量$\vec{v}$都是$\hat{i}$和$\hat{j}$的特定线性组合。</strong><br>若变换后的$\hat{i} = \left[\begin{matrix}<br>-1 \\ 2<br>\end{matrix}\right]$<br>&emsp;$\hat{j} =<br>\left[<br>\begin{matrix}<br>3 \\ 0<br>\end{matrix}\right]$<br>则变换后的</p>
<script type="math/tex; mode=display">\vec{v} = -1\hat{i} + 2\hat{j}= -1\left[
\begin{matrix}
-1 \\
2 
\end{matrix}\right]
+2
\left[\begin{matrix}
3 \\
0
\end{matrix}\right]=
\left[\begin{matrix}
5 \\
2
\end{matrix}
\right]</script><p><img src="Image/08.png" width="100%"><br>可知一个二维变换仅由$\vec{i}$和$\vec{j}$的坐标四个数字即可完全确定。</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
\color{green}{-1} & \color{red}{3} \\
\color{green}{2} & \color{red}{0}
\end{matrix}
\right]</script><p>因此我们可以用$2\times2$<strong>矩阵</strong>来描述二维线性变换的信息。  </p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
\color{green}{a} & \color{red}{b} \\
\color{green}{c} & \color{red}{d}
\end{matrix}
\right]</script><p>第一列$(a, c)$可以看作是变换后的第一个基向量。<br>第二列$(b, d)$可以看作是变换后的第二个基向量。<br>把矩阵与向量<br>$\left[<br>\begin{matrix}<br>x \\<br>y<br>\end{matrix}<br>\right]<br>$相乘，就是将线性变换作用于该向量。<br><img src="Image/09.png" width="100%"><br>把矩阵列看作变化后的基向量，矩阵向量乘法即可看作是基向量的线性组合。 </p>
<h1 id="矩阵乘法与线性变换复合"><a href="#矩阵乘法与线性变换复合" class="headerlink" title="矩阵乘法与线性变换复合"></a>矩阵乘法与线性变换复合</h1><h2 id="复合变换"><a href="#复合变换" class="headerlink" title="复合变换"></a>复合变换</h2><p>连续做两次线性变换，例如先将整个平面逆时针旋转90度再做剪切变换，</p>
<script type="math/tex; mode=display">
旋转变换\left[
\begin{matrix}
\color{green}{0} & \color{red}{-1} \\
\color{green}{1} & \color{red}{0}
\end{matrix}
\right]
剪切变换\left[
\begin{matrix}
\color{green}{1} & \color{red}{1} \\
\color{green}{0} & \color{red}{1}
\end{matrix}
\right]</script><p><img src="Image/01.gif" width="100%"></p>
<p>总体效果是一个新的单独的线性变换，这样得到的新的变换称为两个变换的<strong>复合变换</strong>。因此也可以用一个新的矩阵来表示。新矩阵应当捕捉到了先旋转再剪切的总体效应。  </p>
<p><img src="Image/10.png" width="100%"><br><img src="Image/11.png" width="100%"></p>
<h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><p>根据上文，所有向量经过这样的复合变换的结果都应该相同。<br>因此复合矩阵可以看作剪切矩阵和旋转矩阵的乘积。</p>
<script type="math/tex; mode=display">
\left[
\begin{matrix}
\color{green}{1} & \color{red}{1} \\
\color{green}{0} & \color{red}{1}
\end{matrix}
\right]
\left[
\begin{matrix}
\color{green}{0} & \color{red}{-1} \\
\color{green}{1} & \color{red}{0}
\end{matrix}
\right]=
\left[
\begin{matrix}
\color{green}{1} & \color{red}{-1} \\
\color{green}{1} & \color{red}{0}
\end{matrix}
\right]</script><p>由此得知，<strong>两个矩阵相乘，实质就是两个线性变换相继作用</strong>（作用顺序为从右向左）。</p>
<h3 id="矩阵乘法运算原理"><a href="#矩阵乘法运算原理" class="headerlink" title="矩阵乘法运算原理"></a>矩阵乘法运算原理</h3><p>以上述复合矩阵为例，分步详解矩阵乘法的规律。<br>右侧矩阵可以视为已经变换过一次的基向量$\hat{i}$与$\hat{j}$。<br>此时：</p>
<script type="math/tex; mode=display">\hat{i} = \left[
\begin{matrix}
\color{green}{0}\\
\color{green}{1}
\end{matrix}
\right]</script><script type="math/tex; mode=display">
\hat{j} = \left[
\begin{matrix}
\color{red}{-1}\\
\color{red}{0}
\end{matrix}
\right]</script><p>让基向量进行第二步剪切变换：</p>
<script type="math/tex; mode=display">
\hat{i} = \left[
\begin{matrix}
\color{green}{1} & \color{red}{1} \\
\color{green}{0} & \color{red}{1}
\end{matrix}
\right]
\left[
\begin{matrix}
\color{green}{0}\\
\color{green}{1}
\end{matrix}
\right]=
\left[
\begin{matrix}
\color{green}{1}\\
\color{green}{1}
\end{matrix}
\right]</script><script type="math/tex; mode=display">\hat{j} = \left[
\begin{matrix}
\color{green}{1} & \color{red}{1} \\
\color{green}{0} & \color{red}{1}
\end{matrix}
\right]
\left[
\begin{matrix}
\color{red}{-1}\\
\color{red}{0}
\end{matrix}
\right]=\left[
\begin{matrix}
\color{red}{-1}\\
\color{red}{0}
\end{matrix}
\right]</script><p>由复合变换后的基向量，即可得到最终的复合矩阵：</p>
<script type="math/tex; mode=display">
\left[
\begin{matrix}
\color{green}{1} & \color{red}{-1} \\
\color{green}{1} & \color{red}{0}
\end{matrix}
\right]</script><p>同理，这个方法具有普适性<br><img src="Image/12.png" width="100%"></p>
<h3 id="复合变换的运算律"><a href="#复合变换的运算律" class="headerlink" title="复合变换的运算律"></a>复合变换的运算律</h3><ol>
<li>不满足交换律 <script type="math/tex">M_1M_2 \neq M_2M_1</script></li>
<li>满足结合律（不变更顺序） <script type="math/tex">A(BC) = (AB)C</script><br>用数值证明结合律，运算量十分庞大。<br>但其本质都是从右到左，先进行B变换再进行A变换。</li>
</ol>
<p>三维下的线性变换与矩阵乘法的原理及运用与二维下的基本一致。<br><img src="Image/13.png" width="100%"></p>
<h1 id="行列式"><a href="#行列式" class="headerlink" title="行列式"></a>行列式</h1><h2 id="二维情况"><a href="#二维情况" class="headerlink" title="二维情况"></a>二维情况</h2><p>在线性变换时，会对网格线内部的空间造成伸缩或挤压。<br><img src="Image/02.gif" width="100%">  </p>
<p>想要测量变换究竟对空间进行了多少拉伸或挤压，可以计算一个给定大小的区域增大或减小的比例。</p>
<p><img src="Image/03.gif" width="100%"></p>
<p>把$\hat{i}$为底、$\hat{j}$帽为边的正方形作为单位面积，只要知道这个正方形面积变化的比例，就能得知其他任意区域的面积变化比例（其他区域的面积会与单位区域的面积有相同的变化，因为线性变换中网格线保持平行且等距分布）。</p>
<p>这个特殊的缩放比例，即线性变换改变面积的比例，被称为这个变换的<strong>行列式</strong>。</p>
<script type="math/tex; mode=display">det\bigg(
\left[
\begin{matrix}
\color{green}{3} & \color{red}{0} \\
\color{green}{0} & \color{red}{2}
\end{matrix}
\right]\bigg) = 6</script><p>若一个二维线性变换的行列式为0，说明它将整个平面都压缩为一条线甚至一个点上，此时矩阵的列线性相关。<br><img src="Image/04.gif" width="100%"><br>只要检验一个矩阵的行列式是否为0，就能了解这个矩阵所代表的变换是否能把空间压缩到更小的维度上。</p>
<h3 id="二维下行列式负值的意义"><a href="#二维下行列式负值的意义" class="headerlink" title="二维下行列式负值的意义"></a>二维下行列式负值的意义</h3><p>行列式负值的意义：<br>初始状态，$\hat{i}$向量在$\hat{j}$向量的左侧。<br>经过变换，$\hat{i}$向量在$\hat{j}$向量的右侧。</p>
<p><img src="Image/05.gif" width="100%"></p>
<p>此时空间定向发生了改变。</p>
<p>以二维空间为例，基向量$\hat{i}$逆时针逐渐靠近$\hat{j}$，行列式的值逐渐趋近于0。</p>
<p><img src="Image/06.gif" width="100%"></p>
<p>当在$\hat{i}$与$\hat{j}$重合时，行列式的值为0。<br>照此趋势继续运动，行列式的值会减小为负值。</p>
<h2 id="三维情况"><a href="#三维情况" class="headerlink" title="三维情况"></a>三维情况</h2><p>三维空间中行列式的值代表着体积的缩放比例。<br><img src="Image/14.png" width="50%"><br>它的棱处于基向量$\hat{i},\hat{j},\hat{k}$上。</p>
<h3 id="三维下行列式负值的意义"><a href="#三维下行列式负值的意义" class="headerlink" title="三维下行列式负值的意义"></a>三维下行列式负值的意义</h3><p>根据右手定则来判断：<br><img src="Image/15.png" width="30%"><br>此时行列式为正。</p>
<p><img src="Image/16.png" width="30%">  </p>
<p>只能用左手表示时，说明定向发生改变，行列式为负。</p>
<h2 id="行列式的计算"><a href="#行列式的计算" class="headerlink" title="行列式的计算"></a>行列式的计算</h2><h3 id="二阶行列式"><a href="#二阶行列式" class="headerlink" title="二阶行列式"></a>二阶行列式</h3><script type="math/tex; mode=display">det\bigg(
\left[
\begin{matrix}
\color{green}{a} & \color{red}{c} \\
\color{green}{b} & \color{red}{d}
\end{matrix}
\right]\bigg) = ad - bc</script><p>原理：假设$b$与$c$为0，则a与d分别表示单位长方形伸缩后形成的矩形的底和高，面积为$ad$。<br><img src="Image/17.png" width="100%"><br>若$b$与$c$不为0，则它们会告诉我们原矩形在对角线方向上被拉伸或压缩了多少，通过计算同样可以得出最终的行列式大小$ad-bc$。<br><img src="Image/18.png" width="100%">  </p>
<h3 id="三阶行列式"><a href="#三阶行列式" class="headerlink" title="三阶行列式"></a>三阶行列式</h3><p>三阶行列式的原理与二阶行列式相同。<br>计算时一般使用代数余子式。<br><img src="Image/19.png" width="100%">  </p>
<h1 id="逆矩阵、列空间、秩与零空间"><a href="#逆矩阵、列空间、秩与零空间" class="headerlink" title="逆矩阵、列空间、秩与零空间"></a>逆矩阵、列空间、秩与零空间</h1><h2 id="逆矩阵"><a href="#逆矩阵" class="headerlink" title="逆矩阵"></a>逆矩阵</h2><p>有一个线性方程组</p>
<script type="math/tex; mode=display">\left\{
\begin{aligned}
2x + 5y + 3z &= -3 \\
4x + 0y + 8z &= 0 \\
1x + 3y + 0z &= 2
\end{aligned}
\right.</script><p>可以把这个线性方程组合并为一个向量方程:</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
2 & 5 & 3 \\
4 & 0 & 8 \\
1 & 3 & 0
\end{matrix}
\right]
\left[
\begin{matrix}
\color{green}{x}\\
\color{red}{y}\\
\color{blue}{z}
\end{matrix}
\right]=
\left[
\begin{matrix}
-3\\
0\\
2
\end{matrix}
\right]</script><p>该方程由一个包含全部常数系数的矩阵($A$)、一个包含所有未知量的向量($\vec{x}$)与它们乘积得到的一个常数向量($\vec{v}$)组成。<br>记作：  </p>
<script type="math/tex; mode=display">A{\color{blueviolet}{\vec{x}}} = \color{yellow}{\vec{v}}</script><p>矩阵$A$代表一种线性变换，求解$A{\color{blueviolet}{\vec{x}}} = \color{yellow}{\vec{v}}$意味着我们去寻找一个向量$\vec{x}$，使得它在变换后与$\vec{v}$重合。  </p>
<div align="center"><img src="Image/20.png" width="50%"></div>  

<p>在$A$的行列式不为0时，有且仅有一个向量在变换后与$\vec{v}$重合，并且可以通过逆向变换来找到这个向量。<br>当我们进行逆向变换时，我们实质上进行了另一个线性变换，称作$A$的逆，记作$A^-1$。<br>先应用A代表的变换，再应用A逆代表的变换，会回到原始状态。<br>在代数上体现为矩阵乘法：</p>
<script type="math/tex; mode=display">{A^-1}A = E</script><p>这个什么都不做的变换被称为<strong>恒等变换</strong>，得到的结果是<strong>单位矩阵</strong>。<br>在得知逆矩阵的情况下，可以通过在$A{\color{blueviolet}{\vec{x}}} = \color{yellow}{\vec{v}}$两侧同乘$A^-1$得到最终的$\vec{x}$。</p>
<script type="math/tex; mode=display">{A^-1}A{\color{blueviolet}{\vec{x}}} = {A^-1}\color{yellow}{\vec{v}}</script><script type="math/tex; mode=display">{\color{blueviolet}{\vec{x}}} = {A^-1}\color{yellow}{\vec{v}}</script><p>但是，在$A$的行列式等于0时，不存在逆变换。因为此时的维度降低了。不能试图逆向将一个点通过一个变换得到多个向量。<br>然而，即使$det(A) = 0$，只要压缩后的直线恰好与$\color{yellow}{\vec{v}}$在同一条直线上，解$\color{blueviolet}{\vec{x}}$仍然可以存在。</p>
<div align="center"><img src="Image/21.png" width="100%"></div> 

<h2 id="列空间"><a href="#列空间" class="headerlink" title="列空间"></a>列空间</h2><p>不管变换结果是一条直线，一个平面还是三维空间，所有可能的变换结果的集合都被称作矩阵的<strong>列空间</strong>（变换后的基向量张成的空间）。 </p>
<h2 id="秩"><a href="#秩" class="headerlink" title="秩"></a>秩</h2><p><strong>秩</strong>是列空间的维数。<br>当变换后的结果是一条直线时，我们称这个变换的结果是一维的，该变换的秩为1。<br>当变换后向量的结果落在一个二维平面上，则称该变换的秩为2。<br>当秩达到最大值时，秩与列数相等，我们称之为<strong>满秩</strong>。</p>
<p>零向量一定在列空间中，因为线性变换原点的位置不变。<br>对满秩变换来说，变换后唯一落在原点的就是零向量自身。</p>
<div align="center"><img src="Image/07.gif" width="100%"></div> 
但是非满秩的变换会把空间压缩到更低的维度上。会有一系列向量变成零向量。
<div align="center"><img src="Image/08.gif" width="100%"></div>
例如一个三维线性变换将空间压缩到一条直线上，那么会有一整个面的空间被压缩到原点。
<div align="center"><img src="Image/09.gif" width="100%"></div>  

<h2 id="零空间"><a href="#零空间" class="headerlink" title="零空间"></a>零空间</h2><p>变换后落在原点的向量的集合，被称为矩阵的<strong>零空间</strong>或<strong>核</strong>。<br>对线性方程组来说，如果最终的结果$\color{yellow}{\vec{v}}$是零向量，零空间给出的就是该向量方程可能的解。</p>
<h1 id="点积与对偶性"><a href="#点积与对偶性" class="headerlink" title="点积与对偶性"></a>点积与对偶性</h1><h2 id="非方阵矩阵的意义"><a href="#非方阵矩阵的意义" class="headerlink" title="非方阵矩阵的意义"></a>非方阵矩阵的意义</h2><p>以$<br>\left[<br>\begin{matrix}<br>2 &amp; 0\\<br>-1 &amp; 1\\<br>2 &amp; 1<br>\end{matrix}<br>\right]<br>$为例：<br>这是一个3$\times$2的矩阵。该矩阵只有两个基向量，但这两个基向量都是三维向量。也就是说，该矩阵的几何意义就是把二维空间映射到三维空间上，该矩阵的列空间就是三维空间中的一个平面。</p>
<h2 id="点积的运算"><a href="#点积的运算" class="headerlink" title="点积的运算"></a>点积的运算</h2><p>把两个向量的相应坐标配对相乘再相加。</p>
<script type="math/tex; mode=display">
\left[
\begin{matrix}
2\\
3\\
4
\end{matrix}
\right]\cdot
\left[
\begin{matrix}
5\\
8\\
2
\end{matrix}
\right]=2\times5 + 3\times8 + 4\times2</script><h2 id="点积的几何意义"><a href="#点积的几何意义" class="headerlink" title="点积的几何意义"></a>点积的几何意义</h2><p>两个向量点积等于一个向量$\vec{w}$在另一个向量$\vec{v}$上的投影长度与$\vec{v}$的模长的乘积。</p>
<div align="center"><img src="Image/22.png" width="100%"></div>  

<p>若它们相互垂直，则点积结果为0。<br>若它们的夹角大于90&deg;，则点积结果为负。</p>
<p>点积与顺序无关，可以把$\vec{w}$投影到$\vec{v}$上计算也可以反过来把$\vec{v}$投影到$\vec{w}$上再进行计算。<br>原理如下：<br>$\vec{w}$与$\vec{2v}$的点积可以看作是$\vec{w}$的投影长度乘以2倍$\vec{v}$的模长。<br>$\vec{w}\cdot2\vec{v}=|\vec{w}|cos\theta\times2|\vec{v}|$</p>
<div align="center"><img src="Image/23.png" width="100%"></div>

<p>也可以看作是$\vec{v}$的投影长度的2倍乘以$\vec{w}$的模长。<br>$\vec{w}\cdot2\vec{v}=|\vec{w}|\times2|\vec{v}|cos\theta$</p>
<div align="center"><img src="Image/24.png" width="100%"></div> 

<p>总体效果相同，仍然是点积变为原来的两倍。  </p>
<h2 id="点积的本质"><a href="#点积的本质" class="headerlink" title="点积的本质"></a>点积的本质</h2><p>为什么点积的运算会与投影有所联系？  </p>
<div align="center"><img src="Image/10.gif" width="100%"></div> 
以多维空间到一位空间（数轴）的线性变换来理解，基向量变换后的位置是数轴上的一个点，因此矩阵上的每列只是一个单独的数。
<div align="center"><img src="Image/11.gif" width="100%"></div>

<p>假设我们有一个向量$\vec{v}=<br>\left[<br>\begin{matrix}<br>4 \\<br>3<br>\end{matrix}<br>\right]<br>$与一个线性变换$<br>\left[<br>\begin{matrix}<br>1 &amp;-2<br>\end{matrix}<br>\right]$  </p>
<div align="center"><img src="Image/12.gif" width="100%"></div>

<p>把$\vec{v}$分解为$4\hat{i}$与$3\hat{j}$，根据线性变换性质可得$\hat{i}$与$\hat{j}$分别变换成了数字1和-2，可得：</p>
<script type="math/tex; mode=display">\vec{v} = 4\hat{i} + 3\hat{j} = 4 \times1 + 3 \times -2 = -2</script><p>或写作：</p>
<script type="math/tex; mode=display">\vec{v}=
\left[
\begin{matrix}
4 \\
3
\end{matrix}
\right]
\left[
\begin{matrix}
1 &-2
\end{matrix}
\right] = -2</script><p>以上运算在感觉上就像两个向量的点积一样。$1\times2$矩阵就像一个倾倒的向量。<br>这说明把向量转换为数的线性变换和这个向量本身有着某种关系。</p>
<div align="center"><img src="Image/25.png" width="100%"></div>

<p>假设存在一个线性变换，可以把空间压缩到二维向量$\hat{u}$所在的数轴上，且$\hat{u}$为单位向量。我们把这个将二维平面投影到了数轴上的变换称为投影变换。</p>
<div align="center"><img src="Image/26.png" width="100%"></div>

<p>为了得到假设的投影变换的矩阵，我们需要考虑变换后$\hat{i}$与$\hat{j}$的位置，也就是$\hat{i}$与$\hat{j}$在数轴上的投影。<br>因为$\hat{u}$与$\hat{i}$都是单位向量，所以它们在对方的投影长度相同。</p>
<div align="center"><img src="Image/27.png" width="80%"></div>

<p>同理可得$\hat{j}$在$\hat{u}$方向上的投影。</p>
<div align="center"><img src="Image/28.png" width="100%"></div>

<p>由此得到描述投影变换的矩阵：</p>
<script type="math/tex; mode=display">
\left[
\begin{matrix}
u_x & u_y
\end{matrix}
\right]</script><p>空间中任意向量$\vec{v}$投影变换的结果（$\vec{v}$与投影矩阵的乘积），与$\vec{v}$和$\hat{u}$的向量点积完全相同。<br>这种投影变换都会有一个向量与其相关联。<br>对任意向量$\vec{v}$作线性变换，其结果和与投影变换的矩阵所关联的向量作点积相同。</p>
<div align="center"><img src="Image/29.png" width="100%"></div>

<p>因此，任意向量$\vec{v}$与单位向量的点积都可以解读为，将$\vec{v}$投影到单位向量所在的直线上所得到的投影长度。</p>
<h1 id="叉积的标准介绍"><a href="#叉积的标准介绍" class="headerlink" title="叉积的标准介绍"></a>叉积的标准介绍</h1><h2 id="二维视角"><a href="#二维视角" class="headerlink" title="二维视角"></a>二维视角</h2><p>$\vec{v}$和$\vec{w}$的叉积等于它们所围成的平行四边形的面积。</p>
<div align="center"><img src="Image/30.png" width="100%"></div>

<p>$\vec{v}$在$\vec{w}$右侧，$\vec{v}$和$\vec{w}$的叉积是正的。</p>
<div align="center"><img src="Image/31.png" width="100%"></div>

<p>反之，$\vec{v}$在$\vec{w}$左侧，$\vec{v}$和$\vec{w}$的叉积是负的。</p>
<div align="center"><img src="Image/32.png" width="100%"></div>

<p>即：</p>
<script type="math/tex; mode=display">\vec{v}\times\vec{w}=-\vec{w}\times\vec{v}</script><h3 id="二维下叉积的计算"><a href="#二维下叉积的计算" class="headerlink" title="二维下叉积的计算"></a>二维下叉积的计算</h3><p>$\vec{v}$与$\vec{w}$的叉积等于以$\vec{v}$与$\vec{w}$为列的行列式（教科书上一般把向量写在行上，但本质上二者等价，写在列上更方便理解）。</p>
<div align="center"><img src="Image/33.png" width="100%"></div>

<p>在定向发生改变后，$\vec{v}$与$\vec{w}$的行列式正负改变，叉积正负亦改变。</p>
<div align="center"><img src="Image/34.png" width="100%"></div>

<h2 id="真正的叉积（三维视角）"><a href="#真正的叉积（三维视角）" class="headerlink" title="真正的叉积（三维视角）"></a>真正的叉积（三维视角）</h2><p>真正的叉积的结果并非一个数字，而是一个向量。<br>该向量的长度等于$\vec{v}$与$\vec{w}$围成的平行四边形的面积，并垂直于这个平行四边形所在的平面。</p>
<div align="center"><img src="Image/35.png" width="100%"></div>
其方向的判定遵从右手定则。
<div align="center"><img src="Image/36.png" width="60%"></div>

<h3 id="三维下叉积的运算"><a href="#三维下叉积的运算" class="headerlink" title="三维下叉积的运算"></a>三维下叉积的运算</h3><div align="center"><img src="Image/37.png" width="100%"></div>
三维下两向量的叉积也可以通过行列式计算。
运算结果是一个线性组合：
<div align="center"><img src="Image/38.png" width="100%"></div>

<p>但是为什么行列式第一列是三个基向量？这个线性组合的几何意义又是是什么？</p>
<h2 id="从线性变换的角度理解叉积"><a href="#从线性变换的角度理解叉积" class="headerlink" title="从线性变换的角度理解叉积"></a>从线性变换的角度理解叉积</h2><p>为说明这个问题，我们定义一个从三维到一维的线性变换。  </p>
<div align="center"><img src="Image/39.png" width="100%"></div>

<h3 id="如何理解叉积的运算"><a href="#如何理解叉积的运算" class="headerlink" title="如何理解叉积的运算"></a>如何理解叉积的运算</h3><p>向量$\vec{v}$和$\vec{w}$固定，通过输入向量$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$<br>以得到这三个向量所构成的平行六面体的面积的值（符号根据定向确定）。<br>这相当于一个从三维到一维的线性变换（$\vec{v}$和$\vec{w}$均为常量），因此可以通过$1\times3$矩阵来描述它。  </p>
<div align="center"><img src="Image/40.png" width="100%"></div>

<p>与点积类似，可以找到一个与该线性变换等价的对偶向量。<br>对$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$进行变换等价于让$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$与变换的对偶向量进行点乘。</p>
<div align="center"><img src="Image/41.png" width="100%"></div>

<div align="center"><img src="Image/42.png" width="100%"></div>

<p>从计算角度来看，叉积运算得到的线性组合的系数实际就是对偶向量$\vec{p}$的坐标。<br>第一列的$\hat{i}$、$\hat{j}$和$\hat{k}$是为了告诉我们应该把这些系数解读为一个向量的坐标。</p>
<div align="center"><img src="Image/43.png" width="50%"></div>

<h3 id="如何理解叉积的几何意义"><a href="#如何理解叉积的几何意义" class="headerlink" title="如何理解叉积的几何意义"></a>如何理解叉积的几何意义</h3><p>此时问题变为了：找到一个$\vec{p}$，使其满足</p>
<script type="math/tex; mode=display">\vec{p}\cdot
\left[
\begin{matrix}
x \\ y \\z
\end{matrix}
\right]=det\bigg(
\left[
\begin{matrix}
x & v_1 & w_1\\
y & v_2 & w_2\\
z & v_3 & w_3
\end{matrix}
\right]\bigg)</script><p>假设$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$不垂直于$\vec{v}$和$\vec{w}$所构成的平面，那么$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$、$\vec{v}$、$\vec{w}$所构成的平行六面体的体积，就等于$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$在垂直于$\vec{v}$、$\vec{w}$所构成的平面的方向的分量长度乘以这一平面的面积。</p>
<div align="center"><img src="Image/44.png" width="100%"></div>

<p>这与用垂直与平行四边形平面且长度等于平行四边形面积的向量与$<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$点乘是一致的。</p>
<div align="center"><img src="Image/45.png" width="100%"></div>

<p>总结：<br>一、根据$\vec{v}、\vec{w}$定义一个从三维到一维的变换。<br>二、通过两种等价的方式（变换和点乘）考虑该变换的对偶向量。</p>
<ol>
<li>体积（底乘高） = 平行四边形的面积 $\times$ $<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$垂直于$\vec{v}、\vec{w}$的分量的长度  </li>
<li>体积（点积） =  $\vec{p}\ \cdot ~<br>\left[<br>\begin{matrix}<br>x \\ y \\z<br>\end{matrix}<br>\right]$ </li>
</ol>
<p>二者等价，那么在几何意义上，所求的$\vec{p}$必须满足“垂直于$\vec{v}、\vec{w}$且长度为平行四边形面积”，就是我们所求的对偶向量$\vec{p}$的几何性质。<br>三、得到结论：$\vec{p}$就是$\vec{v}与\vec{w}$的叉积。</p>
<h1 id="基变换"><a href="#基变换" class="headerlink" title="基变换"></a>基变换</h1><p>我们在用坐标描述向量时，都与当前选取的坐标系有关，而坐标系由基向量所决定。同一个坐标在不同坐标系下有着不同的意义。</p>
<h2 id="同一坐标于不同坐标系间的转换"><a href="#同一坐标于不同坐标系间的转换" class="headerlink" title="同一坐标于不同坐标系间的转换"></a>同一坐标于不同坐标系间的转换</h2><p>如何完成同一个坐标在不同坐标系间的转换？<br>例如，如何在我们的坐标系中表示以<br>$\vec{b_1}=\left[<br>\begin{matrix}<br>\green2 \\ \green1<br>\end{matrix}<br>\right]、\vec{b_2}=\left[<br>\begin{matrix}<br>\red {-1} \\ \red1<br>\end{matrix}<br>\right]$为基的坐标系中的坐标$\left[<br>\begin{matrix}<br>-1 \\ 2<br>\end{matrix}\right]$？<br>用该向量的坐标与其所在坐标系的基向量数乘，即可得到结果，这样的运算的本质等价对向量作以其所在坐标系的基向量为列的矩阵的线性变换。</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
\green2 &  \red{-1}\\
\green1 & \red1
\end{matrix}
\right]\left[
\begin{matrix}
-1 \\ 2
\end{matrix}
\right]=
-\left[
\begin{matrix}
\green2 \\ \green1
\end{matrix}
\right]+2\left[
\begin{matrix}
\red{-1} \\ \red1
\end{matrix}
\right]=
\left[
\begin{matrix}
-4 \\ 1
\end{matrix}
\right]</script><p><img src = "Image/46.png"></p>
<p>上述运算的得到了以我们视角下的坐标。该矩阵的基向量$\vec{b_1}、\vec{b_2}$也是以我们的视角看待的。</p>
<p>这一次，我们真正地从另一个坐标系的视角来看待。<br>如何在以$\vec{b_1}、\vec{b_2}$为基的坐标系中表示我们眼中的<br>$\left[\begin{matrix}<br>3 \\ 2<br>\end{matrix}<br>\right]<br>$?<br>我们需要取我们视角下基变换矩阵的逆：</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
\green2 &  \red{-1}\\
\green1 & \red1
\end{matrix}
\right]^{-1} = \left[
\begin{matrix}
1/3 &  1/3\\
-1/3 & 2/3
\end{matrix}
\right]</script><p>再对我们眼中的$\left[\begin{matrix}<br>3 \\ 2<br>\end{matrix}<br>\right]$作该逆变换即可：</p>
<script type="math/tex; mode=display">\left[
\begin{matrix}
1/3 &  1/3\\
-1/3 & 2/3
\end{matrix}
\right]\left[\begin{matrix}
3 \\ 2
\end{matrix}
\right]=\left[\begin{matrix}
5/3 \\ 1/3
\end{matrix}
\right]</script><p>所以$\left[\begin{matrix}<br>5/3 \\ 1/3<br>\end{matrix}\right]$就是转换为$\vec{b_1}、\vec{b_2}$为基的坐标系视角下的我们视角下的$\left[\begin{matrix}3 \\ 2<br>\end{matrix}\right]$。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>基变换矩阵把我们的网格转换为其他人的网格，得到<strong>我们视角下</strong>的其他人的向量。</p>
<script type="math/tex; mode=display">我们的网格\rightarrow其他人的网格\\
我们的视角\leftarrow其他人的视角</script><p>对基变换矩阵求逆则把其他人的网格转换为我们的网格，得到<strong>其他人视角</strong>下的我们的向量。</p>
<script type="math/tex; mode=display">其他人的网格\rightarrow我们的网格\\
其他人的视角\leftarrow我们的视角</script><p>已知其他人视角下的向量$\vec{v}$与基向量，与我们视角下的一个线性变换$M$，如何得到变换后的其他人视角下的$\vec{v}$？<br>已知其他人的基向量，也就是已知基变换矩阵$A$。</p>
<p>根据我们上面所学的知识，运算步骤如下：</p>
<ol>
<li>把$\vec{v}$转换到我们的视角下：<script type="math/tex; mode=display">A\vec{v}</script></li>
<li>因为$A\vec{v}$已经在我们视角下，因为可以直接做我们视角的变换：<script type="math/tex; mode=display">MA\vec{v}</script></li>
<li>最后把我们视角下变换后的向量$MA\vec{v}$转换回其他人的视角：<script type="math/tex; mode=display">A^{-1}MA\vec{v}</script></li>
</ol>
<p>$A^{-1}MA\vec{v}$就是我们想要的结果。<br>$A^{-1}MA$形式的变换暗示着一种数学上的转移作用，中间的矩阵是我们所见的变换，两侧的矩阵则表示视角的转化。</p>
<h1 id="特征向量与特征值"><a href="#特征向量与特征值" class="headerlink" title="特征向量与特征值"></a>特征向量与特征值</h1><h2 id="二维空间中的特征向量"><a href="#二维空间中的特征向量" class="headerlink" title="二维空间中的特征向量"></a>二维空间中的特征向量</h2><p>考虑二维空间中的某个线性变换，我们关注其对一个特定向量的作用，并考虑这个向量张成的空间（即通过原点与向量尖端的直线），会发现大部分向量在变换中脱离了张成的空间。</p>
<div align="center"><img src="Image/13.gif" width="100%"></div>

<p>但是，确实存在某些向量留在了它张成的空间内，这意味着矩阵对这些向量的作用仅仅是拉伸或压缩。</p>
<div align="center"><img src="Image/14.gif" width="100%"></div>

<p>这些特殊向量称为<strong>特征向量</strong>，这些向量在变换后被拉伸或压缩的倍数被称为<strong>特征值</strong>。<br>特征值可以为负，意味着经过变换特征向量的方向扭转了。</p>
<div align="center"><img src="Image/15.gif" width="100%"></div>

<h2 id="三维空间的特征向量"><a href="#三维空间的特征向量" class="headerlink" title="三维空间的特征向量"></a>三维空间的特征向量</h2><p>在三维空间中，如果能找到一个旋转变换的特征向量，就说明找到了这个变换的旋转轴。且在这种情况下特征值必须为1，因为旋转不缩放任何向量。</p>
<div align="center"><img src="Image/16.gif" width="100%"></div>

<p>把三维旋转看作绕旋转轴旋转一定角度，比考虑相应的$3\times 3$矩阵直观得多。</p>
<h2 id="特征向量概念"><a href="#特征向量概念" class="headerlink" title="特征向量概念"></a>特征向量概念</h2><p>用符号表示特征向量的概念：</p>
<script type="math/tex; mode=display">A\vec{v}= \lambda\vec{v}</script><p>对特征向量$\vec{v}$作变换$A$，可以看作对$\vec{v}$作了某个数$\lambda$倍的拉伸。</p>
<p>求一个矩阵的特征向量与特征值，也就是求使这个等式成立的向量$\vec{v}$与数$\lambda$。<br>把等号右侧写作与左侧意义相同的矩阵向量乘积形式：</p>
<script type="math/tex; mode=display">A\vec{v}= (\lambda I)\vec{v}</script><script type="math/tex; mode=display">(A-\lambda I)\vec{v}= 0</script><p>这样一来我们就得到了一个新矩阵$(A-\lambda I) = \left[<br>\begin{matrix}<br>2-\lambda &amp; 2\\<br>1 &amp; 3-\lambda<br>\end{matrix}<br>\right]$<br>由此可知特征向量就是与矩阵$(A-\lambda I)$相乘结果为0的向量。</p>
<p>若$\vec{v}$是零向量，等式自然成立，因为零向量的位置与大小均不变。但研究零向量没有意义，因此研究特征向量时不包括零向量在内。</p>
<p>如果$\vec{v} \neq 0$，只有矩阵$(A-\lambda I)$等于0才能使方程可解。<br>根据之前有关行列式的知识，只有矩阵代表的变换把空间压缩到更低维度时，才会存在非零向量与矩阵的乘积为零向量。</p>
<p>这样的矩阵行列式为零，即:</p>
<script type="math/tex; mode=display">det(A-\lambda I) = det\bigg(\left[
\begin{matrix}
2-\lambda & 2\\
1 & 3-\lambda
\end{matrix}
\right]\bigg) = 0</script><p>这样就可以通过行列式解得特征值$\lambda = 1$。</p>
<div align="center"><img src="Image/17.gif" width="100%"></div>

<p>进一步求解：</p>
<script type="math/tex; mode=display">\left[\begin{matrix}
1 & 2\\
1 & 2
\end{matrix}\right]\vec{v} = \left[\begin{matrix}
1 & 2\\
1 & 2
\end{matrix}\right]\left[\begin{matrix}
x \\ y
\end{matrix}\right] = 0</script><script type="math/tex; mode=display">x-2y=0</script><p>可以得到一个解$x=2$、$y=-1$。</p>
<div align="center"><img src="Image/18.gif" width="100%"></div>

<p>解得特征向量$\vec{v}=\left[\begin{matrix}<br>2 \\ -1<br>\end{matrix}\right]$，特征值$\lambda = 1$，特征向量变换后仍停留在它张成的空间$(x-2y=0)$里。</p>
<p>二维变换并不一定都有特征向量，例如旋转变换：</p>
<script type="math/tex; mode=display">
\left[\begin{matrix}
0 & -1\\
1 & 0
\end{matrix}\right]</script><script type="math/tex; mode=display">det\bigg(\left[\begin{matrix}
-\lambda & -1\\
1 & -\lambda
\end{matrix}\right]\bigg) = 0</script><script type="math/tex; mode=display">
\lambda^2 = 1</script><p>$\lambda$没有实数解，因此旋转变换没有特征向量。</p>
<p>以剪切变换为例：</p>
<div align="center"><img src="Image/19.gif" width="100%"></div>

<script type="math/tex; mode=display">
\left[\begin{matrix}
1 & 1\\
0 & 1
\end{matrix}\right]</script><script type="math/tex; mode=display">det\bigg(\left[\begin{matrix}
1-\lambda & 1\\
0 & 1-\lambda
\end{matrix}\right]\bigg) = 0</script><script type="math/tex; mode=display">
(1-\lambda)^2 = 0</script><p>解得特征值$\lambda = 1$， 与几何上的结果一致。</p>
<p>一个矩阵可能有多个特征向量，它们的特征值也可能相同或不同。<br>一个把所有向量拉伸为两倍的矩阵<br>$\left[\begin{matrix}<br>2 &amp; 0 \\<br>0 &amp; 2<br>\end{matrix}\right]$，唯一的特征值为2，但平面内每一个向量都是特征向量。</p>
<p>如果基向量恰好是特征向量，会发生什么？<br>除对角线外都为零的矩阵被称为<strong>对角矩阵</strong>，其所有基向量都是特征向量，矩阵的对角元就是他们的特征值。</p>
<script type="math/tex; mode=display">\left[\begin{matrix}
2 & 0 & 0 & 0 & 0\\
0 & 3 & 0 & 0 & 0\\
0 & 0 & 1 & 0 & 0\\
0 & 0 & 0 & 4 & 0\\
0 & 0 & 0 & 0 & 5\\
\end{matrix}\right]</script><p>对角矩阵的优点在于，矩阵多次与自己相乘的结果更容易运算。<br>因此可以结合基变换简化矩阵的幂运算：<br>计算$\left[\begin{matrix}<br>3 &amp; 1 \\<br>0 &amp; 2<br>\end{matrix}\right]^{100}$时，先用$\left[\begin{matrix}<br>3 &amp; 1 \\<br>0 &amp; 2<br>\end{matrix}\right]$的特征向量构成基变换矩阵$\left[\begin{matrix}<br>1 &amp; -1 \\<br>0 &amp; 1<br>\end{matrix}\right]$，<br>再以特征向量为基的坐标系的视角看矩阵：</p>
<script type="math/tex; mode=display">\left[\begin{matrix}
1 & -1 \\
0 & 1
\end{matrix}\right]^{-1}
\left[\begin{matrix}
3 & 1 \\
0 & 2
\end{matrix}\right]
\left[\begin{matrix}
1 & -1 \\
0 & 1
\end{matrix}\right]=
\left[\begin{matrix}
3 & 0 \\
0 & 2
\end{matrix}\right]</script><p>因为矩阵所处的坐标系的基就是矩阵的特征向量，所以新视角下的矩阵代表的变换只会拉伸或放缩基向量，得到的是一个对角矩阵。</p>
<p>这样的一组由特征向量构成的基向量称作一组<strong>特征基</strong>。</p>
<p>我们已经得到了更易计算的对角矩阵，直接用对角矩阵进行运算后再转换回原来的视角即可。</p>
<p>最终结果为：</p>
<script type="math/tex; mode=display">\left[\begin{matrix}
1 & -1 \\
0 & 1
\end{matrix}\right]
\left[\begin{matrix}
3 & 0 \\
0 & 2
\end{matrix}\right]^{100}
\left[\begin{matrix}
1 & -1 \\
0 & 1
\end{matrix}\right]^{-1}</script><p>但是，只有至少拥有一组特征基的矩阵才能通过其简化运算。</p>
<h1 id="抽象向量空间"><a href="#抽象向量空间" class="headerlink" title="抽象向量空间"></a>抽象向量空间</h1><p>从某种意义上说，函数实际是另一种向量。<br>类比两个向量的加法，我们可以将两个函数$f(x)$和$g(x)$相加得到$(f+g)(x)$。<br>类比向量的数乘，函数与实数相乘也有一个合理的解释：就是把输出的值与那个数相乘。</p>
<div align="center"><img src="Image/47.png" width="100%"></div>

<p>由此可见，对向量所作的相加与数乘的操作都可以在函数中复现，那么以向量为背景的线性代数的<strong>线性变换、零空间、点积、特征值</strong>等概念是否能同样运用到函数中呢？</p>
<h2 id="线性的严格定义"><a href="#线性的严格定义" class="headerlink" title="线性的严格定义"></a>线性的严格定义</h2><p>在讨论函数的“线性变换”前，我们先回顾一下线性的定义。<br>若$L$代表一种变换，则满足以下两条性质的变换是线性的：<br>可加性：$L(\vec{v}+\vec{w})=L(\vec{v}) + L(\vec{w})$<br>成比例：$L(c\vec{v}) = c(L\vec{v})$</p>
<p>这两个性质使得一个线性变换可以通过它对基向量的作用来完全描述，这使得矩阵向量乘法成为可能。</p>
<h2 id="函数与线性代数"><a href="#函数与线性代数" class="headerlink" title="函数与线性代数"></a>函数与线性代数</h2><p>回到函数，我们发现函数的求导就是一种线性运算：</p>
<script type="math/tex; mode=display">\frac{d}{dx}(x^3+x^2)=\frac{d}{dx}(x^3)+\frac{d}{dx}(x^2)</script><script type="math/tex; mode=display">\frac{d}{dx}(4x^3)=4\frac{d}{dx}(x^3)</script><p>于是我们尝试用矩阵进行求导，我们先把目光限制在多项式空间上，该空间包含任意高项的多项式：</p>
<div align="center"><img src="Image/48.png" width="100%"></div>

<p>首先我们要赋予该空间坐标的含义，这需要选取一个基。<br>因为多项式已经是数乘$x$的不同次幂再相加的形式，所以我们很自然地选择$x$的不同次幂作为基函数。</p>
<div align="center"><img src="Image/49.png" width="100%"></div>

<script type="math/tex; mode=display">5+3x+x^2=\left[\begin{matrix}
5 \\ 3 \\ 1 \\ 0 \\ 0 \\ \vdots
\end{matrix}\right]</script><p>因为每一个多项式都只有有限项，所以它的坐标就是有限长的一串数加上无限长的一串零。</p>
<div align="center"><img src="Image/50.png" width="100%"></div>

<p>将所有基函数求导后放在对应列，可以得到一个求导矩阵：</p>
<div align="center"><img src="Image/51.png" width="100%"></div>

<p>将任意多项式的向量形式与求导矩阵相乘，得到的就是多项式求导的结果。</p>
<div align="center"><img src="Image/52.png" width="100%"></div>

<p>实际上，我们学到的有关向量的概念在函数中都有对应的内容。<br>|线性代数|函数|<br>|:-:|:-:|<br>|线性变换|线性算子|<br>|点积|内积|<br>|特征向量|特征函数|</p>
<p>实际上，数学中有很多类似于向量的事物，只要我们处理的对象具有数乘和相加的概念，我们在线性代数中所学到的概念都应该适用于它。<br>这些类似向量的事物，例如箭头、一组数或者函数，它们所构成的集合称为向量空间。</p>
<div align="center"><img src="Image/53.png" width="100%"></div>

<p>为了更方便地把已有的向量空间的结论应用于新的向量空间，数学家们定义了向量加法和数乘的公理。</p>
<div align="center"><img src="Image/54.png" width="100%"></div>

<p>这些公理并非基础的自然法则，而是一个媒介。这样一来，人们定义的各种奇怪的向量空间只要符合公理的要求，就可以应用已有的线性代数结论了。</p>
<div align="center"><img src="Image/55.png" width="80%"></div>

<p>对数学家而言，他们只需要根据公理证明结论，再让人们的定义满足公理，就能让人们顺利地应用数学家的结论。而无需把人们定义的各种情况全部考虑一遍。  </p>
<p>这样的代价就是，数学家往往把所得到的结论根据公理抽象地表达出来，使教科书上的定理总是严谨而难以理解。</p>
<p>以数字3为例，遇到具体的情况时3代表着三个物体的集合，但是在数学里3代表着所有的三个物理的集合的抽象概念，而我们也可以将其应用到任何物体上去。</p>
<div align="center"><img src="Image/56.png" width="80%"></div>

<p>向量空间也是如此，它在数学上有很多种体现。但是数学家将其抽象为“向量空间”这样一个无形的概念。<br><strong>普适的代价是抽象</strong>。<br>但我们在学习生活中不妨以更具体、更直观的角度来思考问题，也许可以帮助我们更高效地领略知识之美。</p>
<h1 id="克莱姆法则"><a href="#克莱姆法则" class="headerlink" title="克莱姆法则"></a>克莱姆法则</h1><p>求解矩阵向量乘法意味着求解一个经过线性变换的向量的原向量，让<br>我们从几何的角度思考这一问题。</p>
<script type="math/tex; mode=display">\left[\begin{matrix}
2 & -1 \\ 0 & 1
\end{matrix}\right]
\left[\begin{matrix}
x \\ y
\end{matrix}\right] = 
\left[\begin{matrix}
4 \\ 2
\end{matrix}\right]</script><p>这个由基向量$\hat{i}$和未知的输入向量$(x,y)$围成的平行四边形的面积，恰好等于输入向量的$y$值，因此我们可以用平行四边形的面积表示$y$值。</p>
<div align="center"><img src="Image/57.png" width="80%"></div>
需要注意的是，我们表述的是有向面积（前提是我们把$\hat{i}$放在第一位来定义平行四边形）。
<div align="center"><img src="Image/60.png" width="80%"></div>

<p>同理我们可以用$\hat{j}$与输入向量围成的平行四边形的面积表示$x$值。</p>
<div align="center"><img src="Image/58.png" width="80%"></div>

<p>这种方法也可以应用至三维：</p>
<div align="center"><img src="Image/59.png" width="80%"></div>

<p>当我们进行线性变换时，平行四边形的面积很可能会发生变化。但根据线性变换的定义，所有面积变化的比例都等于线性变换矩阵的行列式。</p>
<div align="center"><img src="Image/61.png" width="80%"></div>

<p>可得：<br>原本的平行四边形的面积 = $y$值<br>变换后的平行四边形的面积 = $y \times det(A)$</p>
<p>所以可以用输出的平行四边形面积(输出向量与$\hat{i}$围成的面积)除以矩阵的行列式计算出$y$：</p>
<script type="math/tex; mode=display">y = \frac{Area}{det(A)} = \frac{det\bigg(\left[\begin{matrix}
2 & 4 \\ 0 & 2
\end{matrix}\right]\bigg)}{det\bigg(\left[\begin{matrix}
2 & -1 \\ 0 & 1
\end{matrix}\right]\bigg)} = 2</script><p>同理可以用输出的平行四边形面积(输出向量与$\hat{j}$围成的面积)除以矩阵的行列式计算出$x$：</p>
<script type="math/tex; mode=display">x = \frac{Area}{det(A)} = \frac{det\bigg(\left[\begin{matrix}
4 & -1 \\ 2 & 1
\end{matrix}\right]\bigg)}{det\bigg(\left[\begin{matrix}
2 & -1 \\ 0 & 1
\end{matrix}\right]\bigg)} = 3</script><p>解得输入向量$\left[\begin{matrix}<br>2 \\ 3<br>\end{matrix}\right]$。</p>
<p>三维情况下也可以用同样的思维求解输入向量。</p>
<p>线性代数的本质笔记至此完结。</p>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2022/03/28/Test/" rel="prev" title="Test">
                  <i class="fa fa-chevron-left"></i> Test
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Voimmamored</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  





  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js","integrity":"sha256-r+3itOMtGGjap0x+10hu6jW/gZCzxHsoKrOd7gyRSGY="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
